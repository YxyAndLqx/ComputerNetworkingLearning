2020年2月19日：
	学习《计算机网络自顶向下方法》第三章
	运输层位于应用层和网络层之间，是分层的网络体系结构的重要部分
	3.1 概述和运输层服务
		1.运输层协议为运行在不同主机上的应用进程之间提供了逻辑通信功能
		2.运输层只在端系统中实现
		3.运输层分组被称为运输层报文段
		4.重要事实：网络路由器仅作用于该数据报的网络层字段；即它们不检查封装在该数据报的运输层报文段的字段
		5.运输层协议不仅有TCP和UDP
	3.1.1 运输层和网络层的关系
		1.网络层提供主机之间的逻辑通信，而运输层为运行在不同主机上的进程之间提供逻辑通信
		2.计算机网络中可以安排多种运输层协议，每种协议为应用程序提供不同的服务模型。
		3.运输层协议能够提供的服务常常受制于底层网络层协议的服务模型
		4.运输层协议也能为应用程序提供可靠的数据传输服务
	3.1.2 因特网运输层概述
		1.UDP（用户数据报协议），提供不可靠无连接服务；TCP（传输控制协议），提供可靠的、面向连接的服务
		2.有时也将TCP的运输层分组称为报文段，而常将UDP的分组称为数据报
		3.IP为主机之间提供逻辑通信。IP的的服务模型是“尽力而为的交付服务”所以被称为不可靠服务
		4.将主机间交付扩展到进程间交付被称为运输层的多路复用与多路分解
		5.UDP是一种不可靠服务
		6.TCP提供可靠数据传输，提供拥塞控制
		7.TCP通过流量速率调节使每个进程能平的地共享网络带宽资源，UDO的流量不可调节（用户可调节），使用UDP传输的应用程序可以根据其需要以其愿意的任何速率发送数据（很好的抢带宽特性）
	3.2 多路复用与多路分解
		1.将运输层报文段中的数据交付到正确套接字的工作称为多路分解
		2.在源主机从不同套接字中收集数据块，并为每个数据块封装部首信息从而生产报文段，然后将报文段传递到网络层，这些所有工作称为多路复用
		3.端口号是一个16比特的数，其大小在0~65535之间。0~1023为周知端口号
		4.一个UDP套接字由一个目的IP地址和一个目的端口号标识，两个有不同源端口号，源IP地址，相同目的端口号，目的IP地址的UDP报文将通过相同的目的套接字被定向到相同的目的进程。 
		5.TCP通过4元组（源端口号，源IP地址，目的端口号，目的IP地址）唯一标识一个套接字，与UDP不同的是，两个具有不同源IP地址或源端口号的到达TCP报文段将被定向到两个不同的套接字。
2020-2-20：
	3.3无连接的传输：UDP
		1.UDP只是做了运输协议能够做的最少工作，除了复用/分解功能及少量的差错检测外，它几乎没有对IP增加别的东西
		2.使用UDP时，发送报文之前，发送方和接收方的运输层实体之间没有握手，所以UDP称为无连接的
		3.DNS是一个通常使用UDP的例子。
		4.TCP并不总是首选，UDP可以由应用层更精确地控制何时发送何种数据，UDP无需建立连接，没有连接时延。UDP无连接状态可以支持更多的活跃客户，UDP分组首部开销小
		5.TCP的拥塞控制会导致如因特网电话、视频会议之类的实时应用性能变得很差，所以多媒体应用通常使用UDP
		6.当分组丢包率低时，并且为了安全起见，某些机构阻塞UDP流量。
		7.UDP缺乏拥塞控制能够导致UDP发送方和接收方之间的高丢包率，并挤垮TCP会话，这是一个潜在的严重问题
		8.使用UDP的应用是可以实现可靠数据传输的。将可靠性直接构建于应用程序中可以使其“左右逢源”也就是说应用进程可以进行可靠通信，而无需受制于由TCP拥塞控制机制导致的传输速率限制。
	3.3.1 UDP报文结构
		+--------------------+--------------------+
		|      源端口号      |    目的端口号      |
		+--------------------+--------------------+
		|        长度        |     校验和         |
		+--------------------+--------------------+
		|                应用数据                 |
		|                （报文）                 |
		+-----------------------------------------+
		|_________________________________________|
						  32比特
		UDP首部只有4个字段：长度字段指首部加数据的长度，校验和用于接收方检查是否出现差错
	3.3.2 UDP校验和
	    1.对报文段中的所有16比特字的和进行反码运算，求和时遇到的任何溢出都回卷
		2.端到端原则：因为某种功能必须基于端到端实现：与在较高界别提供这些功能的代价相比，在较低级别上设置的功能可能是冗余或几乎没有价值的。
	3.4 可靠数据传输原理
		1.TCP提供传输数据比特不会受到损害或丢失，而且所有数据都是按照其发送顺序进行交付的服务模型
		2.实现这种服务抽象是可靠数据传输协议的责任
	3.4.1 构造可靠数据传输协议
		1.有限状态机（FSM）
		2.ACK（肯定确认）
		3.NAK（否定确认）
		4.ACK和NAK控制报文是接收方可以让发送方知道哪些内容被正确接收，哪些内容接收有误需要重传。基于这种重传机制的可靠数据传输协议称为自动重传请求协议（ARQ）
		5.ARQ协议还需要差错检测，接收方反馈，重传
		6.发送一个报文等待回复再发送另一个报文的协议称为停等协议。
		7.报文中增加序号字段，接收方可以通过检查序号确定收到的分组是否是一次重传。
		8.确定丢包等待时间，发送方与接收方之间的往返时延，接受方处理一个分组的时间
		9.实践中，发送方等待一个时间，超时即重传，无论是否真的丢包
		10.分组的接受时间必定晚于发送时间
		11.因为分组序号在0和1之间交替，rdt3.0也被称为比特交替协议

	明天还需要仔细研究一下rdt3.0
2020-2-21：
	重看rdt3.0
	3.4.2 流水线可靠数据传输协议
		1.对于rdt3.0这样一个停等协议，在两个端系统之间传播时延RTT=30毫秒，通过一条发送速率R为1Gbps的信道传递分组，其信道利用率仅0.00027
		2.信道利用率：发送方实际忙于将发送比特送进信道的那部分时间与发送时间之比
		3.允许发送多个分组而无需等待确认的技术，称为流水线。
		4.需要为流水线技术增加序号范围
		5.协议的发送方和接收方两端也许必须缓存多个分组。发送方最低限度应当能缓存那些已经发送但是没有确认的分组
		6.所需序号范围和对缓冲的要求取决于数据传输协议如何处理丢失、损坏及延时过大的分组。
		7.解决流水线的差错恢复有两种基本方法，回退N步（GBN)和选择重传（SR）。
	3.4.3 回退N步
		1.回退N步协议，允许发送方发送多个分组而不需要等待确认，但它也受限于在流水线中未确认的分组数不能超过某个最大允许数N
		2.那些已被发送但还未被确认的分组的许可序号范围可以被看成是一个在序号范围内长度为N的窗口。随着协议的运行，该窗口可以在序号空间向前滑动，所以N常被称为窗口长度，GBN协议也常被称为滑动窗口协议。
		3.GBN发送方必须响应三种类型的事件：
			>上层的调用
			>收到一个ACK。对序号为n的分组确认采用累积确认的方式，表明接收方已正确接收到序号为n的以前且包含n在内的所有分组
			>超时事件，超时后协议重传所有发送未确认的分组，回退n步的由来。
		4.接收方丢弃所有失序分组.
		5.这种方法的优点是接收缓存简单，接收方不需要缓存任何失序分组。
2020-2-22：
	3.4.4 选择重传
		1.GBN协议存在性能问题，尤其是当窗口长度和带宽时延积都很大的时候，单个分组的差错就能够引起GBN重传大量分组，许多分组根本没有必要重传。随着信道差错率的增加，流水线可能会被这些不必要的重传分组所充斥。
		2.选择重传（SR）协议通过让发送方仅重传那些它怀疑在接收方出错的分组而避免不必要的重传。
		+-----------------------------------------------------------------------------------------------------------+
		| 1.从上层接收收到数据，SR发送方检查下一个可用序号是否位于窗口内，如果是打包发送，否则缓存或返回上层        |
		| 2.超时，每一个分组都有一个定时器，可以通过一个硬件定时器模拟多个逻辑定时器实现                            |
		| 3.收到ACK，收到ACK，若序号还在窗口内，则标记为已发送，如果序号等于send_base，则窗口向前移动到未确认分组处 |
		+-----------------------------------------------------------------------------------------------------------+
		3.SR接收方将确认一个正确接收的分组而不管器是否按序，失序分组被缓存直到所有丢失的分组皆被收到为止。
		+-----------------------------------------------------------------------------------------------------------+
		| 1.序号在[rcv_base, rcv_base+N-1]内的分组被正确接收，一个选择ACK传回发送方，如果是未接收过的分组，就缓存， |
		|   若序号等于基序号，就向上交付连续的分组，窗口相应向前移动。                                              |
		| 2.收到小于基序号的分组，也发送ACK。                                                                       |
		| 3.其他情况，忽略该分组                                                                                    |
		+-----------------------------------------------------------------------------------------------------------+
		4.如果分组send_base的ACK没有从接收方传回发送方，则发送方将重传分组send_base,即使接收方已经收到该分组，如果接收方不确认该分组，则发送方窗口将永远不能向前滑动。
		5.发送方和接收方的窗口并不总是一致。
		6.当我们面临有限序号范围时，发送方和接收方窗口间缺乏同步将产生很严重的后果。
		7.对于SR协议而言，窗口长度必须小于或等于序号空间大小的一半。
		8.可靠数据传输协议的机制：
		+---------------------------------------------------------------------------------------------------------------------+
		| 1.检验和	         用于检测在一个传输分组中的比特错误                                                               | 
		| 2.定时器           用于超时/重传一个分组，可能因为该分组（或其ACK）在信道中丢失了。由于当一个分组延时但未丢失，或   |
		|					 当一个分组已被接收方收到但从接收方到发送方的ACK丢失时，可以产生超时事件，所以接收方可能会收到一  |
		|					 个分组的多个冗余副本。                                                                           |
		| 3.序号             用于为从发送方流向接收方的数据分组按顺序编号。所接收分组的序号间的空隙可以使接收方检测出丢失的   |
		|                    分组。具有相同序号的分组可使接收方检测出一个分组的冗余副本                                       |
		| 4.确认             接收方用于告诉发送方一个分组或一组分组已被正确接收到了。确认报文通常携带着被确认的分组或多个分组 |
		|                    的序号。确认可以是逐个的或累积的，这取决于协议                                                   |
        | 5.否定确认         接收方用于告诉发送方某个分组未被正确地接收。否定确认报文携带着未被正确接收的分组序号             |
		| 6.窗口、流水线     发送方也许被限制仅发送那些序号落在一个指定范围内的分组。通过允许一次发送多个分组但未被确认，发   |
		|                    送方的利用率可在停等操作模式的基础上得到增加。我们很快将会看到，窗口长度可根据接收方接收和缓存报 |
		|                    文的能力、网络中的拥塞程度或两者情况来进行设置                                                   |
		+---------------------------------------------------------------------------------------------------------------------+
		9.分组重新排序的表现就是：一个具有序号或确认号x的分组的旧副本可能会出现，即使发送方或接收方的窗口中没有包含x。
		10.实际应用中采用的方法是，确保一个序号不被重复使用，直到发送方确信任何先前发送的序号为x的分组都不再在网络中为止。
2020-2-23：
	3.5 面向连接的传输：TCP
		1.TCP是因特网传输层的面向连接的可靠的传输协议。
		2.TCP定义在RFC793、RFC1122、RFC 1323、RFC2018以及RFC2581中。
	3.5.1 TCP连接
		1.TCP发送数据之前，两个进程必须先相互“握手”，即它们必须相互发送某些预备报文段，以建立确保数据传输的参数。
		2.由于TCP协议只在端系统中运行，而不在中间网络元素中运行，所以中间的网络元素不会维持TCP连接状态。
		3.TCP连接提供的是全双工服务。
		4.TCP连接总是点对点的，对于TCP而言，两台主机是一对，而3台主机则太多。
		5.三次握手：客户首先发送一个特殊的TCP报文段，服务器用另一个特殊的TCP报文段来响应，最后，客户再用第三个报文段作为响应。
		 前两个报文段不承载“有效载荷”第三个报文段可以承载有效载荷。
		6.TCP将待发送数据引导到发送缓存里，发送缓存是在三次握手初期设置的缓存之一。
		7.TCP可从缓存中取出并放入报文段中的数据数量受限于最大报文段长度（MSS）
		8.MSS通常根据最初确定的由本地发送的最大链路层帧长度（MTU）来设置。
		9.MSS要保证一个TCP报文段加上TCP/IP首部长度将适合单个链路层帧。
		10.MSS的典型值为1460字节。
		11.注意MSS是指在报文段中应用层数据的最大长度，而不是指包括TCP首部的TCP报文段的最大长度。
	3.5.2 TCP报文段结构
		|<-------------------------------------32比特----------------------------------->|
		+---------------------+----------------------------------------------------------+
		|                  源端口号               |               目的端口号             |
		+---------------------+----------------------------------------------------------+
		|                                        序号                                    |
		+--------------------------------------------------------------------------------+
		|                                       确认号                                   |
		+--------+--------+---+---+---+---+---+---+--------------------------------------+
		|首部长度|保留未用|URG|ACK|PSH|RST|SYN|FIN|                 接收窗口             |
		+-----------------------------------------+--------------------------------------+
		|               因特网校验和              |               紧急数据指针           |
		+-----------------------------------------+--------------------------------------+
		|                                       选项                                     |
		+--------------------------------------------------------------------------------+
		|                                       数据                                     |
		+--------------------------------------------------------------------------------+
		1.TCP报文首部一般20字节，而Telnet发送的报文段也许只有21字节长。
		2.TCP报文段也有源端口号，目的端口号，和校验和字段。
		3.32比特序号和32比特确认号字段。这些字段被TCP发送方和接收方用来实现可靠数据传输服务
		4.16比特的接收窗口字段，该字段用于流量控制。
		5.4比特的首部长度字段，由于TCP选项字段的原因，TCP首部长度是可变的。
		5.可选与变长的选项字段，该字段用于发送方与接收方协商最大报文长度时，或在高速网络环境下用作窗口调节因子使用。首部字段还有一个时间戳字段
		6.6比特的标志字段，ACK比特用于指示确认字段中的值是有效的，RST、SYN和FIN比特用于连接的建立和拆除，PSH比特被设置时指示接收方立即将数据交付给上层。
			URG比特用来指示报文段里存在着被发送端的上层实体置为“紧急”数据。紧急数据的最后一个字节由16比特的紧急数据指针字段指出。（实际中PSH和URG以及紧急数据
			指针并没有使用）
		7.报文序号是该报文段首字节的字节流编号。
		8.TCP只确认该流中至第一个丢失字节为止的字节，所以TCP又被称为提供累积确认
		9.接收方接收到失序报文，要么丢弃失序报文，要么保留失序字节等待缺少的字节填充间隔。TCP在实际中采用后者。
		10.从客户到服务器的数据的确认被装载在一个承载服务器到客户的数据的报文段中；这种确认时被称为被捎带在服务器到客户的数据报文段中的。
	3.5.3 往返时间的估计与超时
		1.往返时间（RTT）
		2.报文段的样本RTT就是从某报文段被发出到对该报文段的确认被收到之间的时间量。
		3.大多数TCP的实现仅在某个时刻做一次SampleRTT测量。
		4.TCP决不为已经被重传的报文段计算SampleRTT。
		5.由于路由器的拥塞和端系统的负载变化，报文段的SampleRTT值或随之波动。
		6.SampleRTT均值（EstimatedRTT）
		7.EstimatedRTT =（1-α）・EstimatedRTT+α・SampleRTT
		8.在[RFC6298]中给出的α参考值是α=0.125，所以：EstimatedRTT= 0.875・Estimated+α・SampleRTT
		9.在统计学中，这种平均被称为指数加权移动平均（EWMA）
		10.用DevRTT表征RTT的变化。
		11.DevRTT = (1-β)・DevRTT+β・|SampleRTT-EstimatedRTT|
		12.如果SampleRTT波动较小，那么DevRTT的值就会变小，反之变大。β推荐值0.25
		13.超时间隔：TimeoutInterval = EstimatedRTT + 4・DevRTT
		14.推荐的初试TimeoutInterval为1秒，出现超时后TimeoutInterval值会加倍。
2020-2-24：
	3.5.4 可靠数据传输
		1.TCP在IP不可靠的尽力而为的服务至上创建一种可靠数据传输服务
		2.由于定时器开销较大，因此，推荐的定时器管理过程[RFC 6298] 仅适用单一的重传定时器，即使有多个已发送但还未被确认的报文段。
		3.TCP发送方有三个与发送和重传有关的主要事件，TCP从应用程序接收数据；定时器超时和收到ACK。
		4.由于ACK丢失引起的重传数据会被接收端丢失。
		5.同时发送两个报文，第一个报文超时重传并重启定时，只要第二个报文段的ACK在新的超时发生之前到达，则第二个报文段将不会被重传。
		6.同时发送两个报文，第一个报文的ACK丢失，只要第二个报文的ACK在超时之前到达，发送方不会重传这两个报文中的任何一个。
		7.超时间隔加倍，会导致时间间隔在每次重传后呈指数级增长。但是定时器由收到上层数据或者收到ACK事件重启，TimeoutInterval由最近的EstimatedRTT值与DevRTT值推算得到。
		8.7中的修改提供了一种形式受限的拥塞控制。
		9.TCP不使用否定确认。
		10.比期望序号大的失序报文段到达。检测出间隔，立即发送冗余ACK，指示下一个期待字节的序号。
		11.一旦收到3个冗余ACK，TCP就执行快速重传，即在该报文段的定时器过时之前重传丢失的报文段。
		12.TCP更像GBN协议，但是TCP只重传ACK丢失的报文，如果n+1报文段ACK在n报文段超时之前到达，TCP不会重传任何报文段。
		13.对TCP提出的一种修改意见是所谓的选择确认[RFC2018],它允许TCP接收方有选择的确认失序报文段，而不是累积确认最后一个正确接收的有序报文段。
		14.TCP的差错恢复机制更像GBN协议与SR协议的混合体。
	3.5.5 流量控制
		1.TCP为它的应用程序提供流量控制服务，以消除发送方式接收方缓存溢出的可能性。
		2.TCP发送方有可能因为IP网络的拥塞而被遏制；这种形式的发送方的控制被称为拥塞控制。
		3.TCP通过让发送方维护一个接收窗口的变量来提供流量控制。
		4.LastByteRead：主机B上的应用进程从缓存读出的数据流的最后一个字节编号。
		5.LastByteRcvd：从网络中到达的并且已放入主机B接收缓存中的数据流的最后一个字节编号
		6.要使缓存不溢出，LastByteRcvd - LastByteRead <= RcvBuffer
		7.接收窗口rwnd = RcvBuffer - [LastByteRcvd - LastByteRead]
		8.发送方在该连接的整个生命周期须保证：LastByteSent-LastByteAcked <= rwnd
		9.TCP规范要求，当主机B的接收窗口为0时，主机A继续发送只有一个字节数据的报文段。这些报文段将会被接收方确认，最终缓存将开始清空，并且确认报恩将包含一个非零的rwnd值。
		10.UDP不提供流量控制，如果进程从缓存区中读取报文段的速度不够快，那么缓存将会溢出。
2020-2-25：
	3.5.6 TCP连接管理
		1.TCP连接的建立会显著地增加人们感受到的时延。
		2.许多网络攻击，如SYN洪泛攻击，都会利用TCP连接管理的弱点。
		3.客户中的TCP会以以下方式与服务器中的TCP建立一条TCP连接
			第一步：客户端TCP首先向服务端TCP发送SYN标准位置1的SYN报文段，另外客户会随机选择一个初始序号，放置于该起始TCPSYN报文段的序号字段中。
			第二步：一旦TCP SYN报文段到达服务器主机，服务器会为该TCP连接分配缓存和变量，并向该客户TCP发送允许连接的报文段。该允许连接的报文段有时会被称为SYNACK报文段。
			第三步：收到SYNACK之后，客户也为这个连接分配缓存和变量。客户主机再想服务器发送一个报文段以确认（通过将server_isn+1填入报文的确认字段完成）。
		4.创建连接时，在两台主机之间发送了3个分组。所以连接建立的过程也叫做三次握手。
		5.参与到一条TCP连接的两个进程中的任意一个都可以终止该连接。
		6.在一个TCP连接的生命周期中运行在每台主机中的TCP协议在各种TCP状态之间迁移。
		7.SYN洪泛攻击：攻击者发送大量的TCPSYN报文段而不完成第三次握手的步骤，以消耗服务器的资源，造成拒绝服务攻击。
		8.SYN cookie可以防止洪泛攻击：
			1）当服务器收到一个SYN报文，不开半开连接，而是首先用源和目的端口号与IP地址以及秘密数计算一个初始TCP序列号，填入SYNACK中。
			2）当客户是合法的，它返回的确认ACK报文段将会填入初始序列号+1的值。服务器再计算这个报文的SYN coolie与其中的序列号比对。如果刚好是序列号-1则生成一个具有套接字的全开连接
			3）如果客户没有返回ACK报文段，则初始的SYNC并没有对服务器造成伤害。
		9.如果主机上的某一个端口并没有被使用，TCP收到访问这个端口的TCP报文时会将RST标志位置1。
		10.当一台主机接收一个UDP分组，它的目的端口与进行中的UDP套接字不匹配，该主机发送一个特殊的ICMP数据报。
		11.nmap检查某个端口是否开放时的做法，先向该端口发送一个TCPSYN：
			1）如果从目标主机收到一个TCP SYNACK报文段，意味着此端口打开
			2）如果收到TCP RST报文段说明，TCPSYN报文到达了目标主机，但是窗口没有开放
			3）如果什么都没有收到，则报文段可能被中间的防火墙拦截了。
		12.nmap可以还侦查多种信息，包括UDP端口，防火墙配置信息，甚至应用程序的版本和其操作系统。
2020-2-26：
	3.6 拥塞控制原理
		1.分组重传作为网络拥塞的征兆
		2.为了处理网络拥塞原因，需要一些机制以在面临网络拥塞时遏制发送方。
		3.异步传递（ATM），可用比特率（ABR）
	3.6.1 拥塞原因与代价
		1.情况1：两个发送方和一台具有无穷大的缓存的路由器。当发送速率接近R/2时，平均时延会越来越大。当发送速率超过R/2时，路由器中的平均排队分组就会无限增长，源与目的地之间的平均时延也会变得无穷大。
			当分组的到达速率接近链路容量时，分组经历巨大的排队时延。
		2.情况2：两个发送方和一台具有有限缓存的路由器，数据被交付给接收方应用程序的速率变为R/3，发送方必须执行重传以补偿因为缓存溢出而丢弃的分组。
			发送方在遇到大时延时所进行的不必要重传会引起路由器利用其链路带宽来转发不必要的分组副本。
		3.情况3:4个发送方和具有有限缓存的多台路由器及多跳路径，当一个分组沿着一条路径被丢弃时，每个上游路由器用于转发该分组到丢弃该分组而使用的传输容量最终被浪费掉了。
	3.6.2 拥塞控制方法
		1.端到端拥塞控制。在这种方法中，网络层没有为运输层拥塞控制提供显示支持。
		2.TCP必须通过端到端的方法解决拥塞控制，因为IP层不会向端系统提供有关网络拥塞的反馈信息。
		3.TCP报文段的丢失被认为是网络拥塞的一个迹象，TCP会相应减小其窗口长度。
		4.网络辅助的拥塞控制。网络层构建向发送方提供关于网络中拥塞状态的显示反馈信息。
		5.关于源端是增加还是降低其传输速率，XCP协议对每个源提供路由器计算反馈，该反馈携带在分组首部中。
		6.直接反馈信息可以由网络路由器发送给发送方。这种放肆的通知通常采用阻塞分组的形式。
		7.经由接收方的网络反馈，路由器标记或更新从发送方流向接收方的分组中的某个字段来指示拥塞的产生。
	3.6.3 网络辅助的拥塞控制例子：ATM ABR拥塞控制
		1.ATM基本上采用一种面向虚电路（VC）的方法来处理分组交换。
		2.网络交换机上的这种逐VC状态是ATM非常适合执行网络辅助拥塞控制。
		3.当网络轻载时，ABR服务会充分利用空闲的可用带宽；当网络拥塞时，ABR服务会将其传输速率抑制为某些预先确定的最小传输速率。
		4.在数据信元中夹杂有所谓的资源管理信元；这些RM信元可被用来在主机和交换机之间传递与拥塞相关的信息。
		5.EFCI比特，每个数据信元都包含1比特的显式转发拥塞指示比特。
		6.CI和NI比特，RM信元中有拥塞指示比特和无增长比特
		7.ER字段，显式速率字段。
2020-2-27：
	3.7 TCP拥塞控制
		1.TCP的另一个关键部分就是其拥塞控制机制。
		2.TCP必须使用端到端拥塞控制而不是使用网络辅助的拥塞控制。
		3.TCP连接的每一端都是由一个接收缓存、一个发送缓存和几个变量组成。
		4.运行在发送方的TCP拥塞控制机制跟踪一个额外变量，cwnd，拥塞窗口。
		5.在一个发送方中有：LastByteSent-LastByteAcked<=min{cwnd,rwnd}
		6.发送方大概速率是cwnd/RTT字节/秒
		7.将一个TCP发送方的“丢包事件”定义为：要么出现超时，要么收到来自接收方的3个冗余ACK。
		8.因为TCP使用确认来触发增大它的拥塞窗口长度，TCP被说成是自计时。
		9.一个丢失的报文段意味着拥塞，因此当丢失报文段时应当降低TCP发送方的速率。
		10.一个确认报文段指示该网络正在向接收方交付发送方的报文段，因此，当对先前未确认报文段的确认到达时，能够增加发送方的速率。
		11.带宽侦测，TCP调节其传输速率的策略是增加其速率以响应到达的ACK，除非出现丢包事件，此时才减少传输速率。
	慢启动：
		1.慢启动状态cwnd的值以1个MSS开始并且每当传输的报文段首次被确认就增加1个MSS
		2.TCP发送速率起始慢，但是在慢启动阶段以指数增长。
		3.如果存在一个由超时指示的丢包事件，TCP发送方将cwnd设置为1并重新开始慢启动过程。
		4.ssthresh（慢启动阈值）在丢包事件后被设为cwnd/2。
		5.当cwnd的值等于ssthresh时，结束慢启动并且TCP转移到拥塞避免模式。
		6.最后一种结束慢启动的方式是，如果检测到3个冗余的ACK，这时TCP执行一种快速重传并进入快速恢复状态。
2020-2-28:
	拥塞避免
		1.一旦进入拥塞避免状态，cwnd值是上次遇到拥塞时的一半
		2.每个RTT只将cwnd的值增加一个MSS。
		3.当出现超时时，TCP也是将cwnd值设为1，而3个冗余ACK会。TCP将cwnd减半，ssthresh也设为cwnd的一半。
	快速恢复
		1.早期版本TCPTahoe不管是超时还是收到3个冗余ACK都将cwnd置为1个MSS。
		2.TCPReno综合了快速恢复
		3.忽略开始时的慢启动状态，假定丢包由3个冗余ACK而不是超时指示，TCP的拥塞控制是：每个RTT内cwnd线性增加1MSS，然后出现三个冗余ACK事件时cwnd减半。
			因此TCP拥塞控制常被称为加性增，乘性减拥塞控制方法（AIMD）。
		4.TCP Vegas算法在分组丢失发生之前，在源于目的地之间检测路由器中的拥塞；当检测出快要发生的分组丢失时，线性地降低发送速率。
		5.Linux支持多种拥塞控制算法，可以通过配置使用特定版本的TCP。默认为CUBIC算法。
		6.TCP AIMD算法基于大量的工程见解和运行网络中的拥塞控制经验而开发。
2020-2-29:
	对TCP吞吐量的宏观描述
		1.TCP发送数据的速率是拥塞窗口与当前RTT的函数，当窗口是w字节，且当前往返时间是RTT秒时，则TCP的发送速率大约是w/RTT。
		2.假设在连续持续期间RTT和W几乎不变，那么TCP的传输速率在W/(2xRTT)到W/RTT之间变化。
		3.一条连接的平均吞吐量=0.75xW/RTT
	经高带宽路径的TCP
		1.TCP拥塞控制已经演化很多年并仍在持续演化。
		2.以往对因特网有益的东西，不一定对当今HTTP主宰的因特网或具有难以想象的服务的未来因特网还是有益的。
		3.TCP连接的吞吐量公式，该公式作为丢包率（L)，往返时间（RTT）和最大报文段长度（MSS）的函数：一条连接的平均吞吐量=1.22xMSS/RTT√L
		4.为了取得10Gbps的吞吐量，今天的TCP拥塞控制算法仅能容忍2x10^-10的报文丢失概率。
	公平性
		5.所谓瓶颈链路就是对于每条连接，沿着该连接路径上的所有其他段链路都不拥塞，而且与该瓶颈链路的传输容量相比，它们都是充足的传输容量。
		6.如果每条连接的平均传输速率接近R/K，即每条连接都得到相同份额的链路带宽，则认为该拥塞控制机制是公平的。
		7公平性与UDP许多媒体应用经常因为特定原因不在TCP上运行，因为他们不想其传输速率被遏制，即使在网络拥塞的情况下。从TCP的观点来看，运行在UDP上的多媒体应用是不公平的。
		8.即使我们能迫使UDP流量具有公平的行为，但公平性问题仍然没有完全解决。这是因为我们无法阻止基于TCP的应用使用多个并行连接。
2020-3-1：
	3.8小结
		1.运输层协议能够提供的服务经常受下面网络层协议服务模型的限制。
		2.在链路层、网络层、运输层或应用层都可以提供可靠数据传送。
		3.TCP是非常复杂的，它涉及连接管理，流量控制，往返时间估计以及可靠数据传送，但是客户-服务器应用程序不关心TCP复杂性。
		4.没有拥塞控制，网络很容易出现死锁，使得端到端之间很少或没有数据能被传输。
		5.当TCP连接的路径上判断不拥塞时，其传输速率就加性增；当出现丢包时，传输速率就乘性减。
		6.数据报拥塞控制协议（DCCP）提供了一种低开销、面向报文、类似于UDP的不可靠服务，但是具有应用程序可选择的拥塞控制形式，该机制与TCP相兼容。
		7.DCCP能够利用数据交付的预定时间和可靠性之间的折中，但是要对网络拥塞作出响应。
		8.流控制传输协议SCTP是一种可靠的、面向报文的协议，该协议允许几个不同的应用层次的“流”复用到单个SCTP连接上
		9.SCTP也允许数据经两条出路径传输，还具有失序数据的选项交付和一些其他特色。
		10.SCTP的流控制和拥塞控制算法基本上与TCP中的相同。
		11.TCP友好速率控制协议（TFRC）是一种拥塞控制协议而不是一种功能齐全的运输层协议。
		12.TFRC的目标是平滑在TCP拥塞控制中的“锯齿”行为，同时维护一种长期的发送速率，该速率“合理地”接近TCP的速率。
		13.TFRC非常适合诸如IP电话或流媒体等多媒体应用，这种平滑的速率对于这些应用是重要的。
		14.应用层和网络层协议基本运行于网络边缘。
	4 网络层
		1.网络层中的每一台主机和路由器中都有一个网络层部分。
		2.网络层也是协议栈中最复杂的层次之一。
		3.构建网络层分组交付的方法有两种，数据报模式和虚电路模式
		4.网络层的两大核心功能转发和路由选择
		5.转发只涉及单一路由器，而路由选择功能涉及一个网络的所有路由器。
		6.地址转换（NAT）、数据报分段、因特网控制报文协议（ICMP）和IPv6。
		7.路由选择算法的任务是决定从发送方到接收方的好的路径。
	4.1 概述
		1.路由器的主要作用便是将数据报从入链路转发到出链路。
		2.路由器没有网络层以上的部分。
	4.1.1 转发和路由选择
		1.转发。当一个分组到达路由器的一条输入链路时，路由器必须将该分组移动到适当的输出链路。
		2.路由选择。当分组从发送方流向接收方时，网络层必须决定这些分组所采用的路由选择或路径。
		3.计算这些路径的算法被称为路由选择算法。
		4.转发是指将分组从一个输入链路接口转移到适当的输出链路接口的路由器本地动作。
		5.路由选择是指网络范围的过程，以决定分组从源到目的地所采取的端到端路径。
		6.每台路由器具有一张转发表。
		7.路由器通过检查到达分组部首字段的值来转发分组，然后使用该值在该路由器的转发中索引查询。
		8.在任何一种情况下，都是路由器接收路由选择协议报文，该信息被用于配置其转发表。
		9.在某些计算机网络中，实际上有第三种重要的网络功能，即连接建立。
		10.某些网络层体系结构如ATM、帧中继、MPLS，要求从源到目的地沿着所选择的路径彼此握手，以便在给定源到目的地连接中的网络层数据分组能够开始流动之前建立起状态，在网络层，该过程被称为连接建立。
2020-3-2：
	4.1.2 网络服务模型
		1.网络服务模型定义了分组在发送与接收端系统之间的端到端运输特性
		2.网络层提供的特定服务包括：
			1）确保交付。该服务确保分组将最终到达其目的地。
			2）具有时延上限的确保交付。该服务不仅确保分组的交付，而且在特定的主机到主机时延上界（例如100ms）交付。
			3）有序分组交付。该服务确保分组以它们发送的顺序到达目的地。
			4）确保最小带宽。这种网络层读物模仿在发送和接收主机之间的一条特定比特绿的传输链路的行为。
			5）确保最大时延抖动。该服务确保位于发送方的两个相继分组之间的时间量等于在目的地接收到它们之间的时间量（或这种间隔的变化不超过某些特定的值）。
			6）安全性服务。使用仅由源和目的主机所知晓的一个秘密会话密钥，在源主机中的网络层能够加密向目的主机发送的所有数据报负载。在目的主机中的网络层能够解密该负载。
		3.因特网的网络层提供了单一的服务，称为尽力而为的服务。
		4.ATM网络体系结构提供了多重服务模型，意味着可以在相同的网络中为不同的连接提供不同类别的服务。
		5.恒定比特率（CBR）ATM网络服务。是第一种标准化的ATM服务模型
		6.可用比特率（ABR）ATM网络服务。能够为发送方提供反馈信息，一遍控制发送方在MCR和一个允许的峰值信元速率之间调整其速率。
2020-3-3：
	4.2 虚电路和数据报网络
		1.尽管网络层连接和无连接服务与运输层面向连接和无连接的服务有相似之处，但也存在重大差异：
			1）在网络层中，这些服务是由网络层向运输层提供的主机到主机的服务。在运输层中，这些服务则是运输层向应用层提供的进程到进程的服务。
			2）所有的计算机网络体系结构中，网络层只提供主机到主机的无连接服务或者主机到主机的的连接服务之一。
			3）提供连接服务的计算机网络称为虚电路网络，仅在网络层提供无连接服务的计算机网络称为数据报网络。
			4）网络层连接服务除了在端系统中，也在位于网络核心的路由器中实现。
			5）虚电路网络和数据报网络是计算机网络的两种基本类型。
	4.2.1 虚电路网络
		1.ATM，帧中继属于虚电路网络，这些网络层称为虚电路。
		2.一条虚电路的组成如下：
			1）源和目的主机之间的路径（即一系列链路或路由器）；
			2）VC号，沿着该路径的每段链路的一个号码；
			3）沿着该路径的每台路由器中的转发表表项
		3.无论何时跨越一台路由器创建一条新的虚电路，转发表就增加了一个新表项。类似的无论何时终止一条虚电路，沿着该路径每个表中的相应项被删除
		4.分组不保持单一VC号的原因，1）逐链路代替该号码减少了在分组首部的VC字段长度。2）通过允许沿着该虚电路路径每条链路一个不同的VC号，大大简化了虚电路建立。
		5.在虚电路网络中，该网络的路由器必须为进行中的连接维持连接状态信息。
		6.在虚电路中有3个不同的阶段：
			1）虚电路建立。在建立阶段，发送运输层与网络层联系，指定接收方地址，等待网络建立虚电路。
			2）数据传送。一旦虚电路创建，分组就可以开始沿该虚电路流动了。
			3）虚电路拆除，当发送方或接收方通知网络层它希望终止该虚电路时，就启动这个阶段。然后网络层通常通知网络另一侧的端系统结束呼叫，并更新路径上的每台分组路由器中的转发表
				以表明该虚电路已经不存在了。
		7.运输层的连接建立仅涉及两个端系统。对于虚电路网络层，沿两个端系统之间的所有路由器都要参与到虚电路的建立中，且每台路由器都完全知道经过它的所有虚电路。
		8.端系统向网络发送指示虚电路启动与终止的报文，以及路由器之间传递的用于建立虚电路的报文，它们被称为信令报文。交换和谐报文的协议称为信令协议。
	4.2.2 数据报网络
		1.在数据报网络中，每当一个端系统要发送分组，它就为该分组加上目的端系统的地址，然后将分组推送到网络中。
		2.无需建立任何虚电路，路由器不维护任何虚电路的状态信息，因为根本没有。
		3.当分组从源到目的地传输，它通过一系列路由器传递。这些路由器中的每台都使用分组的目的地址来转发该分组。
		4.路由器使用地址段来确定转发端口。
		5.路由器使用分组的目的地址的前缀与转发表中的表项进行匹配；如果存在匹配项，则路由器向与该匹配项相联系的链路转发分组。
		6.当有多个匹配时，路由器使用最长前缀匹配原则。
		7.数据报网络服务器在其转发表中维持了转发状态信息，但是转发状态信息表变化时间尺度较慢。
		8.在数据报网络中的转发表是通过路由选择算法进行修改的。这通常每1~5分钟更新一次转发表。
		9.从一个端系统到另一个端系统发送一系列分组可能在通过网络时走不同的路径，并可能无序到达。
	4.2.3 虚电路和数据报网络的由来
		1.作为一条重要的组织原则，虚电路的概念来源于电话界，它采用了真正的电路。由于呼叫建立及每呼叫的状态要在网络中的路由器上维持，一个面向虚电路的网络显然也要比数据报网络要复杂得多。
		2.由于所产生的因特网服务模型使服务保证最少，它对网络层施加了最小限度的需求。
		3.诸如电子邮件、web等应用，甚至如DNS这样的网络基础设施都是在位于网络边缘的主机上实现的。
		4.增加一个新的服务只需要连接一台主机到网络中，并定义一个新的应用层协议即可，这种能力可以使如Web之类的新服务能在短时间内在因特网上得以部署。
2020-3-4：
	4.3 路由器工作原理
		1.网络层转发功能实现从一台路由器的入链路传送到适当的出链路
		2.输入端口。输入端口执行几项关键的功能。它将执行将一条输出的物理链路与路由器相连接的物理层功能
		3.输入端口还要执行需要与位于入链路远端的数据链路层交互的数据链路层功能，
		4.输入端口还要完成查找功能。
		5.控制分组从输入端口转发到路由选择处理器。
		6.交换结构。交换结构将路由器的输入端口与输出端口相连接。
		7.输出端口。输出端口存储从交换结构接收的分组，并通过执行必要的链路层和物理层功能在输入链路传输这些分组。
		8.当一条链路是双向的时，输出端口通常是与该链路的输入端口在同一块线卡上成对出现。
		9.路有选择处理器执行路由选择协议，维护路有选择表以及连接的链路状态信息，并为路由器计算转发表。它还执行网络管理功能。
		10.输入端口，输出端口和交换结构共同实现转发功能，有时总称为路由器转发平面。并由硬件实现
		11.具有10Gbps带宽的输入链路和64字节的IP数据报，其输入端口在另一个数据报到达前仅有51.2ns来处理数据报。如果N个端口结合在一块线路卡上，数据报处理流水线必须以N倍速率运行，这远快过软件实现的速率。
		12.当转发平面以纳秒时间尺度运行时，路由器的控制功能在毫秒或秒尺度上运行。这些路由器控制平面通常由软件实现，并在路有选择处理器上执行。
	4.3.1 输入端口
		1.输入端口的路线端接功能与链路层处理实现了用于各个输入链路的物理层和链路层。
		2.在输入短口中执行的查找对于路由器的运行是至关重要的。
		3.在输出端口路由器使用转发表查找输出端口，使到达分组能经过交换结构转发到输出端口。
		4.转发表由路由器选择处理器计算和更新。端口存着转发表副本，有了这个副本转发决策能在端口本地做，无需经过中央路由选择处理器。
		5.在输入端口处理中1）必须出现物理层和链路层处理，2）必须检查分组的版本号、检验和以及寿命字段3）必须更新用于网络管理的计数器
		6.输入端口查找IP地址然后发送的该分组进入交换结构的步骤是一种更为一般的“匹配加动作”抽象的特定情况，这种抽象执行在许多网络设备中，而不仅在路由器中。
	4.3.2 交换结构
		1.交换可以有内存交换，总线交换，和纵横式交换。
		2.经内存交换最简单，输出端口和输入端口之间的交换都是在CPU的直接控制下完成的
		3.内存交换如果内存带宽为每秒可写进内存或从内存读出B个分组，则总的转发吞吐量必然小于B/2，且不能同时转发两个分组，即使它们有不同的端口号，因为经过共享系统总线一次仅能执行一个内存读写。
		4.总线交换，带宽受总线速率限制，一次只一个报文
		5.经互联网络交换，克服单一共享总线带宽限制。纵横式交换机有2N条总线
		6.纵横式交换可以并行交换分组
	4.3.3 输出端口
		输出端口处理取出存放在输出端口内存中的分组并将其发送到输出链路上。
	4.3.4 何处出现排队
		1.输入端口和输出端口都能出现排队
		2.随队列增长内存耗尽，就会出现丢包
		3.我们说过分组“在网络中丢失”或“被路由器丢弃”，正是在一台路由器的这些队列中。
		4.Rswitch比Rline快N倍则在输入端口处仅会出现微不足道的排队。
		5.缓存数量B应当等于平均往返时延RTT乘以链路的容量C，然而研究表明当大量的TCP流（N）经过一条链路时，缓存所需要的数量是B=RTT・C/√N
		6.输出端口排队的后果就是，在输出端口上的一个分组调度程序必须在这些排队的分组中选出一个发送
		7.可以是先来先服务（FCFS）或者加权公平排队（WFQ）
		8.分组调度程序在提供服务质量保证方面起关键作用。
		9.缓存满时要么删除到达分组要么选一个已排队分组删除。
		10.目前已经有很多分组丢弃与标记策略，这些策略统称为主动队列管理（AQM）算法。随机早期检测（RED)算法
		11.如果交换结构不能快得使所有到达分组无时延地通过它传送，则在输入端口也将出现分组排队
		12.一个分组需要发送的端口虽然没有竞争依然排队的现象叫线路前部阻塞（HOL），即在一个输入队列中排队的分组必须等待通过交换结构发送，因为它被位于线路前部的的另一个分组所阻塞。
		13.由于HOL阻塞，只要输入链路上的分组到达速率到达其容量的58%，在某些假设前提下，输入队列长度将无限制增大。
	4.3.5 路由控制平面
		1.网络范围的路由选择控制平面是分布式，即不同部分执行在不同的路由器上并且通过彼此发送控制报文进行交互。
		2.此外，路由器和交换机厂商将它们的硬件数据平面和网络控制平面绑在一起放入封闭的平台中，称为一种垂直综合的产品。
2020-3-5：
	4.4 网际协议：因特网中的转发和编址
		1.因特网编址和转发是网际网络（IP）的重要组件
		2.因特网网络层有三个重要组件，第一个是IP协议，第二个是路由选择部分它决定数据报从源目的地所流经的路径。第三个是差错和对某些网络层信息请求进行响应的设施。
	4.4.1 数据报格式
		|------------------------32比特-----------------------|
		+-------------+-------------+-------------------------+
		|版本|部首长度|    服务类型 |     数据报长度（字节）  |
		+-------------+-------------+----+--------------------+
		|           16比特标识      |标志|     13比特片偏移   |
		+-------------+-------------+----+--------------------+
		|     寿命    |   上层协议  |        首部校验和       |
		+-------------+-------------+-------------------------+
		|                    32比特源IP地址                   |
		+-----------------------------------------------------+
		|                    32比特目的IP地址                 |
		+-----------------------------------------------------+
		|                    选项（如果有的话）               |
		+-----------------------------------------------------+
		|                         数据                        |
		+-----------------------------------------------------+
		1.版本号。不同IP版本使用不同数据报格式
		2.首部长度。因为有可变数量的选项，所以用这4比特确定IP数据报中数据部分实际从哪开始，大多数报文不含有选项，所以一般IP数据报具有20字节首部。
		3.服务类型，使不同的IP数据报互相区别
		4.数据报长度。指整个数据报长度最大可65535但是实际很少超过1500字节
		5.标识、标志、片偏移。与IP分片有关，IPv6不允许分片
		6.寿命，TTL，每经过一个路由器减一，直到最后为零被丢弃
		7.协议，用于区分最终数据部分交给哪种上层协议，协议号是网络层和传输层的粘合剂，端口号是运输层和应用层的粘合剂
		8.首部校验和。首部校验和用于帮助路由器检查收到的IP数据报中的比特错误。首部校验和：将首部中的每2个字节作为一个数，用反码运算对这些数求和
		9.路由器一般会丢弃检测出错误的数据报。
		10.IP只对IP首部计算校验和，而TCP/UDP对整个TCP/UDP数据报计算校验和。
		11.之所以都要有校验和，TCP/UDP不一定在IP上运行可以是ATM，而IP可以携带非TCP/UDP 的数据。
		12.源和目的IP地址。当某源生成一个数据报时，它在源IP地址字段插入它的IP地址，在目的IP地址字段插入其最终目的地的地址。通常通过DNS查找来决定目的地址。
		13.选项。选项字段允许IP首部扩展。IPv6去掉了IP选项。
		14.数据。可以承载运输层报文段也可以是其他类型的报文段，如ICMP报文段。
		15.一个IP数据报有总长为20 字节的首部，如果数据报承载一个TCP报文段，则每个数据报共承载了总长40字节的首部以及应用报文。
	IP数据报分片
		1.一个链路层帧能承载的最大数据量叫最大传送单元（MTU）
		2.MTU严格限制了IP数报的长度
		3.将IP数报中的数分片成两个或更多较小的IP数据报，用单独的链路层帧封装这些较小的IP数据报，然后向输出链路发送这些帧。每个较小的数据报叫做片。
		4.IPv4的数据报重新组装工作放到端系统中而不是网络路由器中，以简化网络内核。
		5.当生成一个数据报时，发送主机在为该数据报设置源和目的地址的同时再贴上标识号
		6.为了让目的主机绝对的相信它已经收到初始数据报的最后一个片，最后一个片的标志比特置0，其余片的标志比特置1.
		7.为了能让目的主机确定是否丢失一个片，且能按序组装报文，使用偏移字段指定该片应放在初始IP数据报的哪个位置。
		8.如果一个或多个片没有到达目的地，则该不完整的数据报被丢弃且不会交给运输层。
		9.IPv6协议从根本上废除分片，从而简化IP分组处理减少被攻击的可能性。
2020-3-6:
	4.4.2 IPv4编址
		1.一台主机通常只有一条链路连接网络。
		2.当主机中的IP想发送一个数据报时，它就在该链路上发送。主机与物理链路之间的边界叫做接口
		3.一个IP地址技术上是与一个接口相关联的，而不是与包括该接口的主机或路由器相关联的。
		4.地址不能随意选择。一个接口的IP地址的一部分需要由其连接的子网来决定。
		5.为了确定子网，分开主机和路由器的每个接口，产生几个隔离的网络岛，使用接口端接这些隔离的网络的端点。这些隔离的网络中的每个都叫做一个子网。
		6.一个具有多个以太网段和点对点链路的组织将具有多个子网，在给定子网上的所有设备都是具有相同的子网地址。
		7.这种使用单个网络前缀通告多个网络的能力通常称为地址聚合也称路由聚合或路由摘要。
2020-3-7：
		8.因特网的地址分配策略被称为无类别域间路由选择（CIDR）。
		9.形式为a.b.c.d/x的地址的x最高比特构成了IP地址的网络部分，并且经常被称为该地址的前缀（或网络前缀）。
		10.一个地址的剩余32-x的比特可认为是用于区分该组织内部设备的，其中的所有设备具有相同的网络前缀。
		11.在CIDR被采用之前，IP地址网络部分被限制为长度为8、16或24比特，这是一种称为分类编址的编制方案，指示因为具有8、16和24比特子网地址的子网分别被称为A/B/C类网络。
		12.一个组织通过ICANN组织获取一块地址，一台主机通过手动或DHCP获取一个地址
		13.网络管理员能够配置DHCP，以使某给定主机每次与网络连接时能得到一个相同的IP地址，或者某主机将分配一个临时的IP地址，该地址在每次与网络连接时也许是不同的。
		14.由于DHCP具有将主机连接进一个网络的网络相关方面的自动能力，故它又常被称为即插即用协议。
		15.当主句加入或离开时，DHCP服务器要更新其可用的IP地址表。
		16.在最简单场合下，每个子网将具有一台DHCP服务器。
		17.DHCP协议是一个4个步骤的过程：
			1）DHCP服务器发现。一台新的主机的首要任务是发现一个要与其交互的DHCP服务器。这可通过一个DHCP报文来完成。
			2）DHCP服务器提供，DHCP服务器收到一个DHCP发现报文时，用一个DHCP提供报文向客户做出响应，每台服务器提供的报文包含有收到的发现报文的事务ID，向客户推荐的IP地址
				网络掩码以及IP地址租用期，即IP地址有效的时间量。
			3）DHCP请求。新到达客户从一个或多个服务器提供中选择一个，并向选中的服务器提供一个DHCP请求报文进行响应。
			4）DHCP ACK。服务器用DHCP ACK报文对DHCP请求报文进行响应，证实所要求的参数。
		18.网络地址转换（NAT）
		19.具有专用地址的地域是指其地址仅对该网络中的设备有意义的网络。
		20.NAT使能路由器对外部世界来说甚至不像一台路由器。NAT路由器对外界的行为反过来就如同一个具有单一IP地址的单一设备。
		21.从本质上讲，NAT使能路由器对外界隐藏了家庭网络的细节。
		22.路由器从ISP的DHCP服务器得到它的地址，并且路由器运行一个DHCP服务器，为位于NAT-DHCP路由器控制的家庭网络地址空间中的计算机提供地址。
		23.NAT收到IETF团体中的纯化论者大声疾呼反对NAT
		24.第一，他们认为端口号是用于进程编址的，而不是用于主机编址的。
		25.第二，他们认为路由器通常仅应当处理到第三层的分组。
		26.第三，他们认为NAT协议违反了所谓端到端原则，即主机彼此应相互直接对话，节点不应介入修改IP地址和端口号。
		27.第四，他们认为应使用IPv6来解决IP地址短缺问题，而不是不计后果地使用一种如NAT之类的权宜之计来修补存在的问题。
	4.UPnP
	4.4.3 因特网络控制报文协议
	4.4.4 IPv6
		1.IPv6数据报格式
		2.从IPv4到IPv6迁移
	4.4.5 涉足IP安全性
2020-3-8：
	4.5 路由选择算法
		1.当分组到达一台路由器时，该路由器索引其转发表并决定该分组被致死昂的链路接口。
		2.不管网络层提供的是数据报服务，还是虚电路服务，网络层都必须为从发送方到接收方的分组确定所采用的路径。
		3.主机通常直接与一台路由器相连接，该路由器即为该主机的默认路由器，又称该主机的第一跳路由器。
		4.将源主机的默认路由器称为源路由器，吧目的主机的默认路由器称为目的路由器
		5.贼定一组路由器以及连接路由器的链路，路由选择算法要找到一条从源路径到目的路由器的“好路径”
		6.通常一条好路径指具有最低费用的路径。
		7.可以用图来形式化地描述路有选择问题，图G(N,E)是一个N个结点和E条边的集合，其中每条边是取自N的一对结点。
		8.通常，一条边的费用可以反映出对应链路的物理长度、链路速度，或与该链路相关的金融上的费用。
		9.如果（x,y）属于E，结点y也被称为结点x的邻居。
		10.图G=(N,E)中的一条路径是一个结点的序列（x1,x2,……，xp），这样每一个对（x1,x2),(x2,x3),……，(xp-1,xp)是E中的边。路径的费用只是沿着路径所有边的费用的总和，
		11.最低费用路径问题就是找出源和目的之间的具有最低费用路径的一条路。
		12.注意到若在图中的所有边具有相同的费用，则最低费用路径也就是最短路径，即在源和目的地之间的具有最少链路数量的路径。
		13.路由选择算法在一个位置运行，具有该网路的完整信息。是一种集中式的路由选择算法
		14.全局式路由选择算法用完整的、全局性的网络知识计算出从源到目的地之间的最低费用路径。
		15.全局式算法具有关于连通性和链路费用方面的完整信息。实践中，具有全局状态信息的算法常被称作链路状态（LS）算法，因为该算法必须知道网络中每条链路的费用。
		16.分散式路由选择算法以迭代、分布式的方式计算出最低费用路径。
		17.距离向量算法（CV）是一种分散式路由选择算法。之所以叫DV算法，是因为每个节点维护到网络中所有其他结点的费用估计向量。
		18.路由选择算法的第二种广义的分类方式是根据算法是静态的还是动态的进行分类。
		19.静态路由选择算法中，随时间的流逝，路由的变化是非常缓慢的，通常是人工干预进行调整。
		20.动态路由选择算法能够当网络流量负载或拓扑结构发生变化时改变路由选择路径。
		21.虽然动态算法易于对网络的变化做出反应，但也更容易受诸如路有选择循环、路由震荡之类的问题影响。
		22.路有选择算法的第三种分类方式是根据它是负载明发的还是负载迟钝的进行划分。
		23.在负载敏感算法中，链路费用会动态地变化以反映出底层链路的当前拥塞水平
		24.早期ARPAnet就是路由选择算法就是负载敏感的
		25.当今的因特网路由选择算法（RIP、OSPF和BGP）都是负载迟钝的，因为某条链路的费用不明显地反映其当前的拥塞水平。
2020-3-9：
	4.5.1 链路状态路由选择算法
		1.在链路状态算法中，网络拓扑和所有的链路费用都是已知的，也就是说可用作LS算法的输入。
		2.实际中这是通过让每个结点向网络中所有其他结点广播链路状态分组来完成的。
		3.例如使用因特网的OSPF路由选择协议，经常由链路状态广播算法来完成。
		4.所有结点具有该网络的等同的、完整的视图。每个结点都能够像其他结点一样，运行LS算法并计算出相同的最低费用路径集合。
		5.Dijkstra算法计算从某结点到网络中所有其他结点的最低费用路径。Dijkstra算法是迭代算法，其性质是经算法的第k次迭代后，可知道到k个目的结点的最低费用路径，
		6.D(v)：到算法的本次迭代，从源结点到目的结点v的最低费用路径的费用。
		7.p(v):从源到v沿着当前最低费用路径的前一结点（v的邻居）。
		8.N':结点子集；如果从源到v的最低费用路径已确定，v在N'中。
		9.在所有迭代中需要搜索的节点总数为n（n+1）/2, 因此前面实现的链路状态算法在最差情况下复杂性为O(n^2)。
		10.如何解决拥塞敏感的路由选择振荡，一种方法是强制链路费用不依赖于所承载的流量，但是不可接受，因为路由选择就是为了避开高度拥塞的链路
		11.方案二，使执行LS算法的路由器的执行时机不同，但是会出现自同步现象
		12.避免自同步的办法是，让每台路由器发送链路通告的时间随机化。
2020-3-10：
	4.5.2 距离向量路由选择算法
	    （明天再看一遍）今天先不做笔记
2020-3-11：
	4.5.2 距离向量路由选择算法
		1.距离向量算法是一种迭代的、异步的和分布式的算法。LS算法是一种使用全局信息的算法。
		2.此算法是自我终止的，即没有计算应该停止的信号，它就停止了。
		3.Bellman-Ford方程：dx(y)=min(y){c(x,v) + dv(y)}
		4.从x到y的最低费用是对所有邻居v的c（x,v)+dv(y)的最小值。
		5.对Bellman-Ford方程的解为结点x的转发表提供了表项。
		6.每个结点x以Dx(y)开始，对在N中的所有结点，估计从它自己的到结点y的最低费用路径的费用
		7.令D（x）= [Dx(y):y∈N]是结点x的距离向量。
		8.每个费用估计Dx(y) 收敛到dx（y），dx(y)为从结点x到结点y的实际最低费用路径的费用。
		9.当结点x发现它的直接相连的链路费用发生变化或从某个邻居接收到一个距离向量的更新时。它就更新距离向量估计。
		10.为一个给定的目的地y而更新它的转发表，结点x真正需要知道的不是到y的最短路径距离，而是沿着最短路径到y的下一跳路由器邻居结点v*（y).
		11.许多类似DV的算法在实践中被用于多种路由选择协议中，包括因特网的RIP和BGP、ISO IDRP、Novell IPX和早期的ARPAnet。
		12.从邻居接收更新距离向量、重新计算路由选择表项和通知邻居到目的地的最低费用路径的费用已经变化的过程继续下去，直到无更新报文发送为止。
		13.这个时候，因为无更新报文发送，算法进入静止状态。
		14.路由选择环路，为到达x，y通过z路由，z又通过y路由。目的地为x的分组将在y和z之间反复。
		15.毒性逆转，一种对付无穷计数问题，但是更一般的无穷计数问题却不能解决
		16.LS和DV算法的比较：
			1）LS算法要求每个结点知道网络中的每条链路的费用，要发送O(|N||E|)个报文。DV算法要求每次迭代时，在两个直接相邻结点直接交换报文。
			2）收敛速度。LS算法的实现是一个要求O(|N||E|)个报文的O(|N|^2)算法。DV算法收敛慢，且收敛时会遇到路由选择环路。DV算法还会遭遇无穷计数的问题。
			3）健壮性。一个LS结点仅计算自己的转发表，这提供一定的健壮性，DV算法中的一个不正确的结点计算值会扩散到整个网络。
			4）两种算法没有明显的赢家，它们都在因特网中得到应用。
		17.LS算法和DV算法基本上是当前因特网实践中使用的仅有的两种算法。
		18.当每条链路资源需要保留给每条经过该链路的连接时，这些电路交换路由选择算法对分组交换数据网是很有价值的。
2020-3-12：
	4.5.3 层次路由选择
		1.在LS和DV算法的研究中，我们将网络只看作一个互联路由器的集合。
		2.在实践中，随着路由器数量变得很大，涉及路由选择信息的计算、存储以及通信的开销将高到不可实现。
		3.在公共因特网上的所有路由器中广播LS更新所需的开销将导致没有剩余的带宽用来发送数据分组，在如此大量的路由器中迭代的距离向量算法将肯定永远无法收敛。
		4.管理自治。是需要考虑的重要因素，在理想情况下，一个组织应当能够按自己的愿望运行和管理其网络，还要能够将其网络与其他外部网络相连接。
		5.规模和管理自治这两个问题可以由自治系统（AS）来解决，每个AS通常由一组通常处于相同管理控制下的路由器组成。
		6.在相同的AS中的路由器都全部运行相同的路由选择算法。
		7.在一个AS内部有一台或多台路由器将有另外的任务，即负责向在本AS之外的目的地转发分组。这些路由器被称为网关路由器。
		8.如果一个AS仅有一个网关路由器，所有跨AS的分组都通过内部最短路径转发到网关路由器，网关路由器向外转发即可。
		9.从相邻AS获取可达性信息和向该AS中的所有路由器传播可达性信息是两项由自治系统间路由选择协议处理的任务。
		10.因特网中所有AS中都运行相同的AS间路由选择协议，BGP4。
		11.在实践中经常使用一种方法是热土豆路由选择。在这种路由选择中，AS尽可能快地扔掉分组。
		12.一个AS决定想起相邻的AS通告那些目的地时具有很大的灵活性。这是一个策略决定，通常更多地取决于经济问题而非技术问题。
		13.某些一级ISP对它们的整个网络使用一个AS，其他ISP则将它们的ISP划分成数十个互联的AS。
		14.在一个AS内部，所有路由器运行相同的自治系统内部；路由选择协议。在各个AS之间。AS运行相同的AS间路由选择协议。
		15.两种AS内部路由选择协议RIP和OSPF和一种AS间路由选择协议（BGP）。
2020-3-13：
	4.6 因特网中的路由选择
		1.路由选择协议的任务就是要确定数据报在源与目的地之间采用的路径。
		2.每个AS通常又都包含多个子网。
	4.6.1 因特网中自治系统内部的路由选择：RIP
		1.AS内部路由选择协议又称内部网关协议。
		2.历史上两个路由选择协议曾被广泛用于因特网自治系统内的路由选择：路由选择信息协议（RIP）与开放最短路优先（OSPF）
		3.RIP是最早的AS内部因特网路由选择协议之一，且目前仍在广泛使用。
		4.RIP是一种距离向量协议，运行方式很像理想化的DV协议。
		5.RIP使用术语跳，跳是沿着从源路由器到目的子网的最短路径所经过的子网数量。
		6.一条路径的最大费用被限制为15，因此RIP的使用限制在网络直径不超过15跳的自治系统中。
		7.任何一台路由器的的距离向量是从这台路由器到该AS中子网的最短路径距离的当前估计值。
		8.在RIP中路由选择更新信息在邻居之间通过使用一种RIP响应报文来交换，大约每30秒交换一次。
		9.响应报文又被称作RIP通告。
		10.每台路由器维护一张称为路由选择表的RIP表。
		11.一台路由器的路由选择表包括该路由器的距离向量和该路由器的转发表。
		12.虽然RIP版本2允许使用类似于我们在4.4节中学习的路由聚合技术。但是原则上AS内的每一个子网应该在转发表中占一行。
		13.如果一台路由器一旦超过180秒没有从邻居听到报文，则该邻居不再被认为是可达的，要么邻居死机了要么连接的链路中断了。
		14.路由器在UDP上使用端口520相互发送RIP请求与响应报文。
		15.路由器也可通过使用RIP请求报文。请求邻居到指定目的地的费用。
		16.RIP是被当做一个应用层进程来实现的。
		17更多的RIP内容可以看[Quagga 2012]
2020-3-14：
	4.6.2 因特网中自治系统内部的路由选择：OSPF
		1.就像RIP一样，OSPF路由选择也被广泛用于因特网的AS内部路由选择。
		2.OSPF和它的关系密切的表兄弟IS-IS通常都设置在上层的ISP中，而RIP却被设置在下层ISP和企业网络中。
		3.OSPF中的开放一词是指路由选择协议规范是公众可用的。
		4.OSPF的最新版本2，由RFC2328这个公用文档所定义。
		5.OSPF的核心就是一个使用洪泛链路状态信息的链路状态协议和一个Dijkstra最低费用路径算法。
		6.使用OSPF，一台路由器构建了一幅关于整个自治系统的完整拓扑图，然后路由器在本地运行Dijkstra的最短路径算法，以确定一个以自身为根结点的到所有子网的最短路径树。
		7.OSPF不强制如何设置链路权值的策略，但提供了一种机制，为给定链路权值集合确定最低费用路径路由选择。
		8.使用OSPF时，路由器向自治系统内所有其他路由器广播路由选择信息，而不仅仅是向其相邻路由器广播。
		9.即使链路状态未发生变化，它也要周期性地（至少每隔30分钟一次）广播链路状态。
		10.链路状态通告的这种周期性的更新增加了链路状态算法的健壮性。
		11.OSPF通告包含在OSPF报文中。
		12.OSPF报文直接报文直接由IP承载，OSPF其上层协议的值为89，因此OSPF协议必须自己实现诸如可靠报文传输、链路状态广播等功能。
		13.OSPF的优点包括：
			1）安全。能够鉴别OSPF路由器之间的交换。使用鉴别，仅有受信任的路由器能参与一个AS内的OSPF协议，
			2）多条相同费用的路径。当到达某目的地的多条路径具有相同的费用时，OSPF允许使用多条路径
			3）对单播与多播路由选择的综合支持。多播OSPF提供对OSPF的简单扩展，以便提供多播路由选择支持，MOSPF使用现有的OSPF链路数据库，并为现有的OSPF链路状态广播机制增加了一种新型的链路状态通告。
			4）支持在单个路由选择域内的层次结构。也许OSPF最重要的优点是具有按层次结构构造一个自治系统的能力。
		14.一个OSPF自治系统可以配置成多个区域。每个区域都运行自己的OSPF链路状态路由选择算法。
		15.一个区域内的每台路由器都向该区域内的所有其他路由器广播其链路状态。
		16.在一个区域内，一台或多台区域边界路由器负责为流向该区域以外的分组提供路由选择。
		17.一个区域内的每台路由器构想该区域内的所有其他路由器广播其链路状态。
		18.在一个区域内，一台或多台区域边界路由器负责为流向该区域以外的分组提供路由选择。
		19.一个AS内只有一个OSPF区域配置成主干区域。主干区域的主要作用是为AS内其它区域之间的流量提供路由选择。该主干总是包含了AS内的所有区域边界路由器，并且可能还包含了一些非边界路由器。
		20.在AS内的区域间的路由选择要求分组首先路由到一个区域边界路由器，在通过主干路由到位于目的地区域的区域边界路由器，然后在路由到最终目的地。
2020-3-15
	4.6.3 自治系统间的路由选择：BGP
		1.是由RFC4271定义的边界网关协议，版本4是当今因特网中域间路由选择协议事实上的标准。
		2.BGP为每个AS提供了进行以下工作的手段：
			1）从相邻AS出获得子网可达性信息。
			2）向本AS内部的所有路由器传播这些可达性信息。
			3）基于可达性信息和AS策略，决定到达子网的“好”路由。
		3.BGP将网络中所有东西粘合在一起。
		4.在BGP中，路由器对通过使用179端口的半永久TCP连接来交换路由选择信息。
		5.对于每条直接连接位于两个不同的AS中的路由器的链路而言，通常有一条这样的BGPTCP连接，
		6.在AS中的路由器之间还有很多半永久的BGPTCP连接
		7.对于每条TCP连接，位于该连接端点的两台路由器称为BGP对等方。
		8.沿着该连接发送所有BGP报文的TCP连接称为BGP会话
		9.跨越两个ASDEBGP会话称为外部BGP会话（eBGP）。
		10.在同一个AS中的两台路由器之间的BGP会话称为内部BGP会话（iBGP）
		11.BGP使得每个AS知道进过其相邻AS可达那些目的地。在BGP中，目的地不是主机而是CDIR化的前缀。
		12.在任何AS中的网关路由器接收到eBGP学习到的前缀后，该网关路由器将使用它的IBGP会话向该AS中的其他路由器发布这些前缀。
		13.当一台路由器得知一个新前缀时，它为该前缀在其转发表中创建一个表项。
2020-3-16 
	2.路径属性和BGP路由
		1.在BGP中，一个自治系统由其全局唯一的自治系统号（ASN）所标识。
		2.并非所有自治系统都有ASN
		3.AS号也由ICANN分配
		4.当一台路由器通过BGP会话通告一个前缀时，它在前缀中包括一些BGP属性。用BGP术语来说。带有属性的前缀被称为一条路由。
		5.AS-PATH，该属性包含前缀的通告已经通过的那些AS。
		6.路由器通过AS-PATH属性来检测和防止循环通告。
		7.在AS间和AS内部路由选择协议之间提供重要链路后，NEXT-HOP属性具有一种微妙而重要的用途，NEXT-HOP是一个开始某AS-PATH的路由器接口。
		8.路由器使用NEXT-HOP属性正确地配置它们的转发表
		9.使用NEXT-HOP值和AS内部路由选择算法，路由器能够确定到每条对等链路的路径的费用，然后用热土豆路由选择来决定适当的接口。
		10.BGP也包括允许路由器对路由分配偏好测度的属性，以及指示前缀如何插入位于起始AS的BGP的属性。
	3.BGP路由选择
		1.根据这种发布，路由器可能知道到达任何一条前缀的多条路由，在这种情况下路由器必须在可能的路由中选择一条。
		2.路由被指派一个本地偏好值作为它们的属性之一。具有最高本地偏好值的路由将被选择。
		3.在余下的路由中，具有最短AS-PATH的路由将被选择
		4.在余下的路由中，将选择具有最靠近NEXT-HOP路由器的路由。
		5.如果仍留下多条路由，该路由器使用BGP标识符来选择路由。
2020-3-17
	4. 路由选择策略
		1.所有进入桩网络的流量必定是去往该网络，所有离开桩网络的的流量是必定时源于该网络
		2.经由两个不同或更多的提供商连到网络的其余部分的自治系统称为多宿桩网络。
		3.多宿桩网络如果向其邻居通告它没有通向其他目的网络的路径，那么它将起到一个桩网络的作用。
		4.目前还没有强制主干ISP之间如何路由选择的官方标准。
		5.商业运行的ISP们遵从的经验法则是：任何穿越某ISP主干网络的流量必须是其源或目的位于该ISP的某个客户网络中；不然的话这些流量将会免费搭便车通过该ISP的网络。
		6.各个对等协定通常都是ISP双方进行协商，而且经常是对外保密的。
		7.BGP是一个对于公共因特网的AS之间路由选择的事实上的标准。
		8.BGP路由选择表通常包含数以万计的前缀和对应的属性。
		9。在AS之间，策略问题起主导作用。一个给定AS产生的流量不能穿过另一个特定的AS这可能很重要。
		10.扩展一个路由选择算法及其数据结构以处理到到大量网络或大量网络之间的路由选择这种能力，是AS间路由选择的一个关键问题。
		11.由于AS间路由选择是面向策略的，因此所用的路由的质量通常是次要关心的问题。在AS内部，可以使路由选择更多地关注于一条路由实现的性能级别方面。
2020-3-18
	4.7 广播和多播路由选择
		1.在广播路由选择中，网络层提供了从一种源结点到网络中的所有其他结点交付分组的服务；
		2.多播路由选择使单个源结点能够向其他网络结点的一个子集发送分组的副本。
	4.7.1 广播路由选择算法
		1.N次单播实现广播的方法简单，无需新的网络层路由选择协议以及分组复制或转发功能。
		2.第一个缺点是它的效率低。
		3.更为有效的方法是经第一跳仅转发分组的单个副本，然后让第一跳后面的其他端的结点生成并转发任何附加的所需副本，也就是让网络结点本身生成分组的冗余副本。
		4.在使用广播来生成更新单播路由的情况下，基于单播路由选择基础设施来取得广播将是不明智的。
	1.无控制洪泛
		1.该方法要求源结点向它的所有邻居发送分组的副本。
		2.如果图是相连的，这种方案将最终将广播分组的副本交付给该图中的所有结点。
		3.如果该图具有圈，则每个广播分组的一个或多个分组将无休止地循环。
		4.这种广播风暴导致无休止的广播分组的复制，将最终导致在该网络中生成大理朗的广播分组，是的网络变得毫无用处。
	2.受控洪泛
		1.避免广播风暴其实就是选择在何时洪泛分组，何时不洪泛分组。
		2.序号控制洪泛中，源结点将其地址以及广播序号放入广播分组，再向它的所有邻居发送该分组。
		3.当一个结点收到一个广播分组，首先检查序号是否在已转发列表中，如果在，丢掉该分组；如果不在，复制该分组并向该结点的所有邻居转发。
		4.反向路径转发又叫反向路径广播（RPF）
		5.但一台路由器接收到具体给定源地址的广播分组时，仅当该分组到达的链路正好位于它自己的返回其源的最短单播路径上时才向其出链路传输报文，否则丢弃报文。
		6.RPF不使用单播路由选择以实际将分组交付给目的地，它也不要求路由器知道从它自己到源的完整最短路径。
2020-3-19 
	3.生成树广播
		1.虽然序号控制洪泛和RPF避免了广播风暴，但它们不能完全避免冗余广播分组的传输。
		2.每个节点应当仅接收广播分组的一个副本。
		3.图G=（N,E)的生成树是一个图G'=（N,E'),使得E'是E的子集，G'是连通的且不包含圈，且G'包含了在G中的所有初始结点。
		4.如果每段链路具有相应的费用且一棵树的费用就是其链路费用之和，则在该图的所有生成树中费用最小的生成树被称为最小生成树。
		5.提供广播的另一种方法是首先对网络结点构造一棵生成树。
		6.生成树不仅消除了冗余的广播分组，而且一旦合适，该生成树能够被任何结点用于开始广播分组，
		7.一个结点不必知道整棵树，只需要知道它在G中的哪些邻居是生成树的邻居。
		8.与生成树相关的复杂性主要是生成树的生成和维护。
		9.采用基于中心的方法建立一棵生成树时，要定义一个中心结点，或称为汇合点或核。
	4.实践中的广播算法
		1.在实践中，广播协议被用于应用层和网络层。
		2.Gnutella为了在Gnutella对等方之间广播对内容的查询，使用应用级的广播。
		3.在Gnutella网络中的两个分布式应用级对等进程之间的一条链路实际上是一条TCP连接。
		4.Gnutella使用某种形式的序号控制洪泛，其中使用了一个16比特标识符和一个16比特标识符合一个16比特有效载荷描述符，以监测一个接收到的广播查询是否以前已经收到，复制和转发过。
		5.一个洪泛Gnutella请求将仅到达位于从该请求的发起者到给定数量的应用级跳数范围内的对等方。
		6.在OSPF路由选择算法和中间系统到中间系统路由选择算法中使用一种序号控制洪泛来广播链路状态通告（LSA）。
		7.使用洪泛方法，新LSA可能比老LSA先到达。序号可以区别。
		8.年龄字段起到TTL的作用。
		9.初始年龄字段值被置为0，随着洪泛到每一跳而被增加，并且当它位于一台路由器内存中等待洪泛时也会增加。
		10.[RFC789;Perlman 1999] 描绘了一次事故，这次事故中，由于两个故障路由器不正确传输LSA，引起早期版本的LSA洪泛算法使整个ARPAnet瘫痪了。
2020-3-20
	4.7.2 多播
		1、多播分组仅被交付给网络结点的一个子集。
		2.一些新兴的网络应用要求将分组从一个或多个发送方交付一组接收方。
		3.在因特网体系结构中多播数据报使用间接地址来编址。
		4.用一组标识来表示一组接收方，寻址到该组的分组副本被交付给所有与该组相关联的多播接收方，且该组使用这个单一标识符。
		5.在因特网中，这种表示一组接收方的单一标识就是一个D类多播地址。
		6.与一个D类地址相关联的接收方小组被称为一个多播组。
		7.每台主机有一个唯一的IP单播地址，该单播地址完全独立于它所参与的多播组的地址。
		8.IGMP 因特网组管理协议。
	1.因特网络组管理协议
		1.IGMP版本3运行在一台主机主机与其直接相连的路由器之间。
		2.在任意给定时间内至多有几台主机属于一个给定的多播组。
		3.IGMP为一台主机提供手段让它通知与其相连的路由器：在本主机上运行的一个应用程序想加入一个特定的多播组。
		4.由于IGMP的交互范围被局限在本机与其相连的路由器之间，显然需要另一种协议来协调遍及因特网内的多播路由器，以便多播数据报能路由到其最终目的地。后一个功能是由
			网络层多播路由选择算法完成的。
		5.与ICMP类似，IGMP报文也是承载在一个IP数据报中，使用的IP协议号为2.
		6.三种报文：membership_query查询接口上主机已加入的所有多播组集合，主机用membership_report报文响应membership_query报文。以及可选报文leave_group报文，用于离开组。
		7.之所以可选，是因为当无主机响应一个具有给定地址的membership_query报文时，该路由器就推断出已经没有主机在这个多播组了。
		8.这是因特网协议中被称为软状态的一个例子。
		9.状态能够在一次崩溃中丢失，接着自动地由后继的更新报文所恢复。
		10.软状态协议要比硬状态协议控制简单一些。
	2.多播路由选择算法
		1.多播路由选择的目标就是发现一棵链路的树，这些链接连接了所有具有属于该多播组的相连主机的路由器。
		2.使用一棵组共享树的多播路由选择。如同在生成树广播的场合，通过组共享树进行多播路由选择的基础是构建一棵树，该树包含了所有具有属于该多播速的相连主机的边缘路由器。
		3.使用一棵基于源的树的多播路由选择。为多播组中的每个源构造一棵多播路由选择树。实践中使用RPF算法来构造一棵多播转发树，以用于源于源点x的多播数据报。
		4.解决应用RPF时会收到不想要的多播分组这个问题的方法称为剪枝，一台接收到多播分组的多播路由器，如它无加入该组的相连的主机，则它向其上游路由器发送一个剪枝报文。如果一台路由器从
			它下游每台路由器收到剪枝报文，则它向上游转发一个剪枝报文。
	3.在因特网中的多播路由选择
		1.距离向量多播路由选择协议DVMRP实现具有反向路径转发与剪枝算法的基于源的树。使用一种具有剪枝的RPF算法。
		2.协议无关的多播（PIM）路由选择协议可能是应用最广泛的因特网多播路由选择协议。
		3.PIM有稠密模式和稀疏模式
		4.在源特定多播中（SSM），仅允许单一发送方向多播树中发送流量，大大简化树的构造和维护。
		5.PIM和DVMRP配置于一个域中。[RFC4271]定义了对BGP的多协议扩展，使BGP能够为其他协议承载路由选择信息，包括多播信息。
		6.使用多播源发现协议（MSDP）能够将不同的PIM稀疏模式域中的聚集点连接在一起。
		7.应用层多播使用应用层协议在对等方之间提供了内容的多播分发。
		8.目前主要是应用层占上风。
2020-3-21
	5 链路层：链路、接入网和局域网
		1.第一种类型是广播信道，这种信道用于连接有线局域网、卫星网和混合光纤同轴电缆接入网中的多台主机。
		2.因为许多主机与相同的广播信道连接，需要所谓的媒体访问协议来协调帧传播。
		3.在某些场合中可以用中心控制器来协调传输。
		4.第二种类型的链路层信道是点对点通信链路，这在诸如长距离连接的两台路由器之间，或用户办公室计算机与他们所连接的邻近以太网交换机之间等场合经常能够发现。
		5.点到点协议（PPP）
	5.1 链路层概述
		1.将运行链路层协议的任何设备称为结点。
		2.结点包括主机、路由器、交换机和WiFi接入点。
		3.把沿着通信路径连接相邻结点的通信信道称为链路。
		4.为了将一个数据报从源主机传输到目的主机，数据报必须通过沿端到端路径上的各段链路传输。
		5.在通过特定的链路时，传输结点将数据报封装在链路层帧中，并将该帧传送到链路中。
	5.1.1 链路层提供的服务
		1.尽管任一链路层的基本服务都是将数据报通过单一通信链路从一个结点移动到相邻结点，但所提供的服务细节能够随着链路层协议的不同而变化。
		2.成帧。在每个网络层数据报经链路传送之前，几乎所有的链路层协议都要将其用链路层帧封装起来。网络层数据报就插在数据字段中。
		3.链路接入。媒体访问控制（MAC）协议规定了帧在链路上传输的原则。
		4.在仅一个发送方和一个接收方的点对点链路，MAC很简单或没有
		5.当多个结点共享单个广播链路时，MAC协议用于协调多个结点的帧传输。
		6.可靠交付，当链路层协议提供可靠服务时，它保证无差错地经链路层移动每个网络层数据报。
		7.与传输层可靠交付服务类似，链路层可靠交付服务通常是通过确认和重传取得的。
		8.链路层可靠交付通常用于易于产生高差错率的链路，例如无线链路，其目的是本地（差错发生的链路上）纠正一个差错，而不是通过运输层或应用层协议迫使进行端到端的数据重传。
		9.对于低比特差错的链路，包括光纤、同轴电缆和许多双绞铜线链路，链路层可靠交付可能会被认为是一种不必要的开销。许多有线的链路层协议不提供可靠交付服务。
		10.差错检测和纠正。通过让发送结点在帧中包括差错检测比特，让接收结点进行差错检查，以此来完成这项工作。
		11.因特网的运输层和网络层也提供了有限形式的差错检测，即因特网校验和。
		12.链路层的差错检测通常更复杂，并且用硬件实现。差错纠正类似于差错检测，区别在于接收方不仅能检测帧中出现的比特差错，而且能够准确地确定帧中的差错出现的位置。（并纠正）
	5.1.2 链路层在何处实现
		1.链路层的主体部分是网络适配器中实现的。
		2.网络适配器有时也称为网络接口卡。
		3.位于网络适配器核心的是链路层控制器，该控制器通常是一个实现了许多链路层服务（成帧，链路接入，差错检测）的专用芯片。
		4.链路层控制器的许多功能是用硬件实现的。
		5.越来越多的网络适配器被综合进主机的主板，即所谓的局域网在主板配置。
		6.在发送端，控制器取得了由协议栈较高层生成并存储在主机内存中的数据报，在链路层帧中封装该数据报，然后遵循链路接入协议将该链路层帧传送进通信链路中。
		7.在接收端，控制器接收了整个帧，抽取出网络层数据报。如果链路层执行差错检测，则需要发送控制器在该帧的首部设置差错检测比特，由接收控制器执行差错检测。
		8.尽管大部分链路层是在硬件中实现的但部分链路层是在运行于主机CPU上的软件中实现的。
		9.链路层的软件组件实现了高层链路层功能，如组装链路层寻址信息和激活控制器硬件，
		10.在接收端，链路层软件响应控制器中断，处理差错条件和将数据报向上传递给网络层。
		11.链路层是硬件和软件的结合体，即此处是协议栈中软件与硬件交接的地方。
2020-3-22 
	5.2 差错检测和纠正技术
		1.对从一个结点发送到另一个物理上连接的邻近结点的链路层帧中的比特损伤进行检测和纠正，称为比特级差错检测和纠正。
		2.在发送结点，为了保护比特免受差错，使用差错检测和纠正比特来增强数据D。
		3.通常要保护的数据不仅包括从网络层传递下来需要通过链路传输的数据报，而且包括链路帧首部中的链路级的寻址信息、序号和其他字段。
		4.接收方的挑战在于它只接收到D'和EDC'的情况下，确定D'是否和初始的D相同。
		5.差错检测和纠正技术使接收方有时但并非总是检测出已经出现的比特差错。即使采用差错检测比特，也还是可能有未检出比特差错，这就是说，接收方可能无法知道接收的信息中包含着比特差错。
		6.一般而言，差错检测和纠错技术越复杂，导致的开销越大。
		7.3种技术：奇偶校验、检验和方法和循环冗余检测。
	5.2.1 奇偶校验
		1.单个奇偶校验位可能是最简单的差错校验方式
		2.在偶校验方案中，发送方只需包含一个附加的比特，选择它的值，使得这d+1个比特中1的总数是偶数。
		3.采用单个奇偶校验位方式，接收方的操作也很简单。接收方只需要数一数接收的d+1比特中1的数目即可。
		4.但是如果出现了偶数个比特差错，将导致未检出的差错。
		5.如果比特差错的概率小，而且比特之间的差错可以被看作是独立发生的，在一个分组中多个比特同时出错的概率将是极小的。
		6.在这种情况下，单个奇偶校验位可能是足够的了。
		7.在突发差错情况下，使用单比特奇偶校验保护的一帧中未检测出差错的概率能够达到50%。
2020-3-23
		8.二维一般化方案，D中的d个比特被划分为i行j列，对每行和每列计算奇偶值。产生的i+j+1奇偶比特构成了链路层帧的差错检测比特。
		9.使用这种二维奇偶校验方案，包含比特值改变的行和列的校验值都将会出现差错。
		10.因此接收方不仅可以检测到出现单个比特差错的事实，而且还可以利用存在奇偶检验差错的行和列的索引来实际识别发生差错的比特并纠正它。
		11.校验比特本身的单个比特差错也是可以检测和可纠正的。
		12.二维奇偶校验也能够检测但不能纠正一个分组中两个比特差错的任何组合。
		13.接收方检测和纠正差错的能力被称为前向纠错（FEC）。
		14.这些技术通常用于如音频CD这样的音频存储和回放设备中。
		15.FEC技术可以减少所需的发送方的重发的次数。并且避免了不得不等待的往返时延。
	5.2.2 检验和方法
		1.一个简单检验和方法就是将这k比特整数加起来，并且用得到的和作为差错检测比特。
		2.因特网检验和就基于这种方法，即数据的字节作为16比特的整数对待并求和。这个和的反码形成了携带在报文段部首的因特网校验和。
		3.接收方通过对接收的数据的和取反码，并且检测其结果是否为全1比特来检测检验和。
		4.如果这些比特中有任何比特是0，就可以指示出差错。
		5.在TCP和UDP中，对所有字段计算因特网检验和。
		6.其他协议如XTP，对部首计算一个检验和，对整个分组计算一个检验和。
		7.链路层的差错检测在适配器中用专用的硬件实现，他能够快速执行更复杂的CRC操作。
	5.2.3 循环冗余检测
		1.现今的计算机中广泛应用的的差错检测技术基于循环冗余检测编码，CRC编码也称为多项式编码，因为该编码能够将要发送的比特串看作为系数0和1的一个多项式。
		2.发送方和接收方首先必须协商一个r+1比特模式，称为生成多项式，我们将其表示为G。
		3.用CRC进行差错检测的过程因此很简单：接收方用G去除接收到的d+r比特。如果余数为非零，接收方知道出现差错；否则认为数据正确而被接收。

